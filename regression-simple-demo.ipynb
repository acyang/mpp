{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'c:\\\\python35\\\\python35.zip', 'c:\\\\python35\\\\DLLs', 'c:\\\\python35\\\\lib', 'c:\\\\python35', 'c:\\\\python35\\\\lib\\\\site-packages', 'c:\\\\python35\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\1203087\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print (sys.path)\n",
    "from mtds.reader import *\n",
    "from mtds.helper import *\n",
    "from mtds.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read local data of raw (downloaded) VASP format.\n",
    "\n",
    "PATH_BASE = os.path.join(os.getcwd(), '../database')\n",
    "\n",
    "path_bin = os.path.join(PATH_BASE, 'vasp/binary_part')\n",
    "path_bin_all = os.path.join(PATH_BASE, 'vasp/binary')\n",
    "\n",
    "bin_mts = read_vasp_from_dir(path_bin)\n",
    "bin_mts_all = read_vasp_from_dir(path_bin_all)\n",
    "\n",
    "all_materials = dict()\n",
    "all_materials['Binary'] = bin_mts\n",
    "all_materials['Binary_All'] = bin_mts_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Materials:10717\n",
      "Number of USED Materials:3823\n",
      "# of Training Materials: 2561 [Filtered]\n",
      "# of Testing  Materials: 1262 [Filtered]\n"
     ]
    }
   ],
   "source": [
    "# Prepare training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Filter Materials.\n",
    "def mt_filter(mt):\n",
    "    \"\"\"Use this to filter data you don't need.\n",
    "    \"\"\"\n",
    "    return mt['band_gap'] > 0.0\n",
    "#     return mt # use all available.\n",
    "\n",
    "mts_all = bin_mts_all\n",
    "print('Number of All Materials:{}'.format(len(mts_all)))\n",
    "\n",
    "# Filter materials for some condition.\n",
    "mts_used = [mt for mt in mts_all if mt_filter(mt)]\n",
    "print('Number of USED Materials:{}'.format(len(mts_used)))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mts_train, mts_test = train_test_split(mts_used, test_size=0.33, random_state=0)\n",
    "\n",
    "print('# of Training Materials: {} [Filtered]'.format(len(mts_train)))\n",
    "print('# of Testing  Materials: {} [Filtered]'.format(len(mts_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mts_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-13c9d8a2f907>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mcollecting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollecting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmts_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_features_mine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_targets_mine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollecting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmts_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_features_mine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_targets_mine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mts_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Define functions for fetching features and targets.\n",
    "\n",
    "def get_targets_mine(mt):\n",
    "    \"\"\"Return user-defined target.\n",
    "    \"\"\"\n",
    "    return mt['band_gap']\n",
    "#     return mt['elasticity']['elastic_tensor'][0][0]\n",
    "\n",
    "def get_specific_features_mine(mt):\n",
    "    \"\"\"Return specific features.\n",
    "    \"\"\"\n",
    "\n",
    "    target_features = ['density', 'energy_per_atom', 'formation_energy_per_atom']\n",
    "#     target_features = ['density', 'energy_per_atom', 'formation_energy_per_atom', 'volume', 'energy', 'nsites', 'e_above_hull']\n",
    "    \n",
    "    features = zeros(len(target_features)) \n",
    "    \n",
    "    for i in range(len(target_features)):\n",
    "        features[i] = mt[target_features[i]]\n",
    "        \n",
    "    return features\n",
    "    \n",
    "def get_features_mine(mt):\n",
    "    \n",
    "    # Get the boundary of rows and groups of periodic table.\n",
    "    rg_limits = row_group_limits()\n",
    "    \n",
    "    rg_features = get_row_group_density_vec(mt, rg_limits)\n",
    "#     rg_features = getElementDensity(mt)\n",
    "    \n",
    "    spec_features = get_specific_features_mine(mt)\n",
    "    \n",
    "    return np.concatenate((rg_features, spec_features))\n",
    "#     return rg_features\n",
    "\n",
    "\n",
    "# A shortcut for feature target pairing.\n",
    "collecting = lambda x, y, z: [[y(mt) for mt in x], [z(mt) for mt in x]]\n",
    "\n",
    "features_train, targets_train = collecting(mts_train, get_features_mine, get_targets_mine)\n",
    "features_test, targets_test = collecting(mts_test, get_features_mine, get_targets_mine)\n",
    "\n",
    "print('Feature Vector Length: {}'.format(len(features_train[0])))\n",
    "print('Train - # of features: {}, targets: {}'.format(len(features_train), len(targets_train)))\n",
    "print('Test  - # of features: {}, targets: {}'.format(len(features_test), len(targets_test)))\n",
    "\n",
    "table = []\n",
    "for mt in mts_test:\n",
    "    table.append([mt['pretty_formula'], mt['full_formula'], get_targets_mine(mt), mt['material_id']])\n",
    "\n",
    "import tabulate\n",
    "print(tabulate.tabulate(table, headers=['Pretty Formula', 'Full Formula', 'Target', 'Material-ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature Scaling/Preprocessing.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "\n",
    "scaler = StandardScaler() \n",
    "# scaler = RobustScaler()\n",
    "\n",
    "# Do remember learn from training set ONLY.\n",
    "scaler.fit(features_train)\n",
    "\n",
    "# Scale all the features.\n",
    "features_train = scaler.transform(features_train)\n",
    "features_test  = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build ML model(s) with scikit-learn.\n",
    "\n",
    "from sklearn import linear_model, kernel_ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = []\n",
    "params = [i for i in range(1, 5)]\n",
    "\n",
    "# Ridge regression model, alpha is the regularization weight.\n",
    "for p in params:\n",
    "#     model = linear_model.Ridge(alpha = p, fit_intercept=True))\n",
    "\n",
    "    # scikit-learn build in kernels: 'poly', 'rbf', 'laplacian', 'sigmoid'.\n",
    "    # refer to: http://scikit-learn.org/stable/modules/svm.html#svm-kernels\n",
    "    model = kernel_ridge.KernelRidge(kernel='poly', degree = p, alpha = 1.0, gamma = p)\n",
    "    models.append(model)\n",
    "\n",
    "# More about prediction models.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# fitting (training) model(s).\n",
    "for model in models:\n",
    "    model.fit(features_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare training and testing set for later usage.\n",
    "\n",
    "# Collecting data for better arrangement.\n",
    "training_set = aggregate_data(mts_train, features_train, targets_train)\n",
    "testing_set  = aggregate_data(mts_test, features_test, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluation the results.\n",
    "estimators = []\n",
    "for i in range(len(params)):\n",
    "    estimators.append({'name':'Parameter set {}'.format(params[i]), 'regressor':models[i]})\n",
    "\n",
    "print('\\nResults of Training')    \n",
    "show_correlations(estimators, features_train, targets_train)\n",
    "\n",
    "# Cross validation.\n",
    "k_fold = 10\n",
    "scores = []\n",
    "print('\\n============= {}-Fold Cross Validation on Training Set =========='.format(k_fold))\n",
    "for estimator in estimators:\n",
    "    score = cross_val_score(estimator['regressor'], features_train, targets_train, cv=k_fold)\n",
    "    scores.append(score)\n",
    "    print(\"{}: score = {} +- {}\".format(estimator['name'], score.mean(), score.std()*2))\n",
    "\n",
    "display_cv(scores)\n",
    "\n",
    "print('\\nResults of Testing')  \n",
    "\n",
    "show_correlations(estimators, features_test, targets_test)\n",
    "\n",
    "# show_elements_on_ptable([mts_test, mts_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the results.\n",
    "\n",
    "for estimator in estimators:\n",
    "    plot_regression_results(training_set, testing_set, estimator, print_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the error.\n",
    "\n",
    "errors_train = [targets_train - estimator['regressor'].predict(features_train) for estimator in estimators]\n",
    "errors_test  = [targets_test  - estimator['regressor'].predict(features_test) for estimator in estimators]\n",
    "\n",
    "# print(len(errors_train))\n",
    "plot_hist(errors_train, 'Training Error Distribution', 0.1)\n",
    "plot_hist(errors_test, 'Testing Error Distribution', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the errors.\n",
    "\n",
    "abs_error_train = [abs(targets_train - estimator['regressor'].predict(features_train)) for estimator in estimators]\n",
    "abs_error_test  = [abs(targets_test  - estimator['regressor'].predict(features_test)) for estimator in estimators]\n",
    "\n",
    "# print(len(errors_train))\n",
    "plot_hist(abs_error_train, 'Training Error Distribution', 0.1)\n",
    "plot_hist(abs_error_test, 'Testing Error Distribution', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
